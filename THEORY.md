# Теория для курсовой работы: Классификация намерений (v2.0)

## 1. Введение

Представьте, что вы пишете ассистента для управления компьютером. Пользователь может сказать "выключи компьютер", "погаси свет на мониторе" или "заверши работу". Все эти фразы означают одно и то же — **намерение** выключить компьютер. Для программиста это похоже на "умный" `switch-case`, где в качестве `case` выступают нечеткие текстовые команды, а не строгие значения.

**Классификация намерений (Intent Classification)** — это задача машинного обучения, цель которой — определить, что именно хочет пользователь (его "интент"), на основе его текстового запроса. В нашем проекте мы сопоставляем текстовую команду с определенным ID (например, ID `0` для выключения).

## 2. Технологии и инструменты в нашем проекте

Этот проект построен на современном и производительном стеке, который позволяет решать задачи глубокого обучения в экосистеме .NET.

*   **C# и .NET**: Основа нашего приложения. Использование C# дает нам преимущества строгой типизации, высокой производительности и доступа к огромной экосистеме .NET, что идеально подходит для создания надежных и масштабируемых приложений.

*   **TorchSharp**: "Сердце" нашего проекта. Это официальная библиотека от .NET Foundation, которая предоставляет C#-биндинги к **LibTorch** — нативной C++ библиотеке, лежащей в основе знаменитого фреймворка **PyTorch**. TorchSharp позволяет нам определять, обучать и запускать сложные нейросетевые модели, используя всю мощь GPU (через технологию CUDA), но при этом оставаясь в привычной среде C#.

*   **Tokenizers.DotNet**: Для работы с текстом мы используем эту библиотеку, которая является .NET-оберткой над высокопроизводительной библиотекой **`tokenizers`** от компании Hugging Face. Она дает нам доступ к самым современным и быстрым алгоритмам токенизации, таким как `WordPiece`, который используется в нашем проекте.

## 3. Этап 1: Данные и Токенизация (Как компьютер понимает слова)

Нейронные сети не могут работать с текстом напрямую. Им нужны числа. Процесс превращения текста в числа называется **токенизацией**.

1.  **Токенизация**: Мы разбиваем предложение на составные части — **токены**. В нашем проекте используется `WordPiece` токенизатор из библиотеки `Tokenizers.DotNet`. Его преимущество для языков с богатой морфологией (как русский) в том, что он может разбивать незнакомые или сложные слова на известные ему части. Например, слово "переобучился" может быть разбито на "пере", "##обуч", "##ил", "##ся". Это позволяет модели понимать слова, которых она не видела в обучающих данных целиком.

2.  **Словарь (Vocabulary)**: После разбиения на токены у нас есть "словарь" (`tokenizer.json`). Это большая таблица, где каждому уникальному токену сопоставлен уникальный номер (ID).
    *   `"открой"` -> `53`
    *   `"браузер"` -> `10`

3.  **Padding и Маска внимания (Padding & Attention Mask)**: Нейросети обычно обрабатывают данные "пачками" (батчами) для эффективности. В батче все входные последовательности должны быть одинаковой длины. Но предложения у нас разной длины!
    *   **Padding (Выравнивание)**: Мы находим самое длинное предложение в батче и "добиваем" все остальные до этой длины специальными "пустыми" токенами (обычно с ID `0`).
    *   **Маска внимания (Attention Mask)**: Чтобы модель не обращала внимания на эти "пустые" токены, мы создаем для нее "подсказку" — **маску**. Это последовательность из `1` и `0`, где `1` соответствует настоящему токену, а `0` — "пустому". Модель будет игнорировать все, что помечено нулем.

*В коде это реализовано в `DataLoader.cs` в методе `Batchify`.*

---

## 4. Этап 2: Архитектура нейросети (Наш "мозг")

### 4.1. Рекуррентные нейронные сети (RNN)

Прежде чем говорить о LSTM, нужно понять, что такое **рекуррентные нейронные сети (RNN)**.
*   **Проблема**: Обычные нейросети (полносвязные, сверточные) не имеют "памяти". Они обрабатывают каждый вход независимо. Для анализа последовательностей (как текст или музыка) это не подходит, так как важен порядок и контекст.
*   **Решение (RNN)**: RNN можно представить как цикл `for`. На каждом шаге цикла сеть принимает на вход очередной элемент последовательности (например, слово) и **скрытое состояние (hidden state)** с предыдущего шага. На основе этого она генерирует выход и **новое скрытое состояние**, которое передается на следующий шаг. Это скрытое состояние и есть "память" сети.
*   **Проблема RNN**: При обработке длинных предложений возникает **проблема затухающих/взрывающихся градиентов**. Аналогия: игра в "испорченный телефон". Через длинную цепочку людей исходное сообщение сильно искажается. Так же и в RNN: "сигнал" об ошибке из конца длинного предложения почти не доходит до начала, и сеть не может научиться связям между далекими словами.

### 4.2. LSTM — RNN с долгой памятью

**LSTM (Long Short-Term Memory)** — это продвинутый тип RNN, специально созданный для решения проблемы затухающих градиентов.
*   **Решение**: Внутри LSTM, помимо обычного "краткосрочного" скрытого состояния, есть еще и **состояние ячейки (cell state)**. Его можно представить как "конвейерную ленту" или "магистраль", по которой информация может течь через всю последовательность почти без изменений.
*   **"Гейты"**: LSTM управляет этой "магистралью" с помощью трех "вентилей" (гейтов):
    *   **Forget Gate (Вентиль забывания)**: Решает, какую информацию из прошлого стоит стереть с "магистрали".
    *   **Input Gate (Вентиль входа)**: Решает, какая новая информация из текущего слова важна и ее стоит записать на "магистраль".
    *   **Output Gate (Вентиль выхода)**: Решает, какую часть из "магистрали" нужно использовать для генерации выхода на текущем шаге.
Эта архитектура позволяет градиентам беспрепятственно "протекать" по всей последовательности, давая сети возможность улавливать зависимости между очень далекими друг от друга словами.

### 4.3. Наша модель `IntentClassifier.cs` в деталях

Теперь разберем по косточкам нашу конкретную модель.

1.  **Слой эмбеддингов (`Embedding`)**:
    *   `Embedding(vocabSize, embDim: 256)`
    *   **Что делает**: Превращает ID каждого токена в вектор из 256 чисел.
    *   **Почему `embDim: 256`?**: Размерность 256 — это популярный выбор, который обеспечивает хороший баланс между выразительностью (способностью вектора кодировать сложный смысл слова) и вычислительной сложностью. Меньшие значения (64, 128) могут не уловить всех нюансов, а большие (512, 768) требуют больше данных и времени на обучение.

2.  **Слой LSTM (`LSTM`)**:
    *   `LSTM(embDim: 256, hiddenSize: 512, numLayers: 2, bidirectional: true)`
    *   **Что делает**: Обрабатывает последовательность 256-мерных векторов.
    *   **Почему `hiddenSize: 512`?**: Это количество "нейронов" или "единиц памяти" в каждом слое LSTM. Это ключевой параметр, определяющий "емкость" модели. 512 — достаточно большое число, чтобы хранить сложный контекст предложения.
    *   **Почему `bidirectional: true`?**: Двунаправленность. Сеть одновременно читает предложение слева направо и справа налево. Это дает ей полное понимание контекста каждого слова. Выходной вектор для каждого слова будет иметь размерность `512 * 2 = 1024`, так как он конкатенирует выходы "прямого" и "обратного" проходов.
    *   **Почему `numLayers: 2`?**: Мы используем два слоя LSTM, "сложенных" друг на друга. Это позволяет модели строить иерархию признаков: первый слой может научиться улавливать базовые синтаксические структуры, а второй, работая уже с выходами первого, — более сложные семантические зависимости.

3.  **Механизм внимания (`Attention`)**:
    *   **Что делает**: Принимает на вход последовательность 1024-мерных векторов от LSTM (по одному на каждый токен) и вычисляет один-единственный 1024-мерный **контекстный вектор**. Этот вектор является "взвешенной" суммой всех векторов токенов, где веса отражают "важность" каждого токена для решения задачи.
    *   **Зачем?**: Вместо того чтобы просто брать выход LSTM от последнего слова, мы "оглядываемся" на все предложение и фокусируемся на ключевых словах, что делает модель точнее.

4.  **Полносвязные слои (`Linear`) и `Dropout`**:
    *   `Linear(1024, 128)` и `ReLU`: Первый полносвязный слой. Он выполняет роль "бутылочного горлышка", сжимая 1024-мерный контекстный вектор до 128 измерений. Это заставляет модель отбирать только самые важные признаки для классификации. `ReLU` — это простая функция активации, добавляющая нелинейность.
    *   `Dropout(0.5)`: Слой регуляризации. Во время обучения он случайным образом "выключает" 50% нейронов на предыдущем слое. Это заставляет сеть учиться более устойчивым и разнообразным признакам, предотвращая **переобучение**.
    *   `Linear(128, numLabels)`: Финальный классификационный слой. Он принимает 128-мерный вектор признаков и выдает "сырые" оценки (логиты) для каждого из наших `numLabels` классов.

5.  **Функция `Softmax`** (применяется в `Predictor.cs` и неявно в `CrossEntropyLoss`):
    *   Превращает вектор логитов (например, `[-0.5, 2.1, 0.1]`) в вектор вероятностей (например, `[0.05, 0.8, 0.15]`), сумма которых равна 1.

---

## 5. Этап 3: Обучение модели (Как "мозг" учится)

### 5.1. Ключевые компоненты обучения

1.  **Функция потерь (`CrossEntropyLoss`)**: Вычисляет, насколько сильно модель "ошиблась". `CrossEntropyLoss` идеально подходит для задач мультиклассовой классификации.

2.  **Обратное распространение ошибки (`loss.backward()`)**: Алгоритм, который вычисляет "вину" каждого параметра модели в итоговой ошибке.

3.  **Оптимизатор (`Adam`)**: Алгоритм, который, зная "вину" каждого параметра, обновляет его так, чтобы в следующий раз ошибка была меньше.

### 5.2. Гиперпараметры обучения в нашем проекте

Гиперпараметры — это "настройки" процесса обучения, которые мы задаем заранее.

*   **`LearningRate = 0.0005`**: Скорость обучения. Это относительно безопасное стартовое значение для оптимизатора Adam, которое обеспечивает стабильную сходимость без риска "перепрыгнуть" через решение.
*   **`BatchSize = 64`**: Размер батча. Мы обрабатываем по 64 предложения за один шаг обновления весов. Это компромисс между скоростью обучения (большие батчи обучаются быстрее на GPU) и потреблением памяти.
*   **`Epochs = 20`**: Максимальное количество раз, которое мы пройдем по всему обучающему датасету.
*   **`EarlyStoppingPatience = 7`**: Механизм ранней остановки. Если точность на валидационном наборе не улучшается в течение 7 эпох подряд, мы прекращаем обучение. Это экономит время и предотвращает переобучение, так как мы останавливаемся в тот момент, когда модель перестала "учиться" чему-то новому и полезному.

*Весь этот процесс реализован в `Trainer.cs`.*

---

## 6. Этап 4: Инференс (Использование модели)

После обучения модель становится, по сути, статической функцией. Процесс ее использования для предсказания на новых данных называется инференсом.

Этот процесс реализован в `Predictor.cs` и включает в себя:
1.  Загрузку сохраненных весов модели и ее конфигурации.
2.  Предобработку новой текстовой команды (токенизация, создание тензоров).
3.  Прогон данных через модель в режиме `eval()` (без вычисления градиентов и с отключенным dropout).
4.  Применение Softmax для получения вероятностей и выбор класса с наибольшей вероятностью.

Это и есть полный цикл жизни нашей модели — от сырого текста до готового предсказания.
